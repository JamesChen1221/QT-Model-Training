# 機器學習訓練概念完整說明

## 🎯 你的訓練結果解讀

剛才的訓練輸出中，你看到了以下結果：

```
訓練集評估:
  - RMSE: 0.0357
  - MAE: 0.0256
  - R² Score: 1.0000

測試集評估:
  - RMSE: 5.7625
  - MAE: 4.3734
  - R² Score: -2.0099
```

### 這代表什麼？

**訓練集表現完美（R²=1.0）但測試集很差（R²=-2.0）= 嚴重過擬合！**

這是因為：
1. **資料太少**：只有 6 筆資料，訓練集只有 4 筆
2. **特徵太多**：25 個特徵對 4 筆資料來說太多了
3. **模型記住了訓練資料**：但無法泛化到新資料

---

## 📚 訓練概念詳解

### 1. 神經數 / 樹的數量（Model Capacity）

**XGBoost 中的對應概念：**
- `n_estimators=100`：建立 100 棵決策樹
- `max_depth=5`：每棵樹最多 5 層深

**類比神經網路：**
- 神經網路：`[64, 32, 16]` 表示三層，分別有 64、32、16 個神經元
- XGBoost：用樹的數量和深度控制模型複雜度

**如何調整：**
```python
# 資料少時，減少模型複雜度
.build_and_train_model(
    n_estimators=50,    # 減少樹的數量
    max_depth=3,        # 減少樹的深度
    learning_rate=0.1
)
```

---

### 2. 訓練集與測試集（Train/Test Split）

**你的資料分割：**
- 訓練集：4 筆（80%）- 用來訓練模型
- 測試集：2 筆（20%）- 用來評估模型

**為什麼需要分割？**
```
訓練集 → 模型學習 → 測試集驗證 → 評估泛化能力
```

**問題：**
- 2 筆測試資料太少，評估不可靠
- 建議至少 20-30 筆測試資料

---

### 3. 樣本數（Sample Size）

**你的情況：**
- 總樣本：6 筆
- 特徵數：25 個
- **特徵/樣本比 = 25/6 = 4.17**（太高！）

**經驗法則：**
| 樣本數 | 適合的模型 | 特徵數建議 |
|--------|-----------|-----------|
| < 50 | 簡單線性模型 | < 10 |
| 50-500 | 隨機森林、XGBoost | < 50 |
| 500-5000 | 深度學習（小型） | < 100 |
| > 5000 | 深度學習（大型） | 不限 |

**你需要：**
- 至少 100 筆資料才能訓練可靠的模型
- 或減少特徵數到 5-10 個

---

### 4. 噪音（Noise）與過擬合（Overfitting）

**什麼是噪音？**
- 資料中的隨機誤差
- 不相關的變化
- 測量誤差

**過擬合的跡象：**
```
✓ 訓練集 R² = 1.0    （完美！）
✗ 測試集 R² = -2.0   （災難！）
→ 模型「死記硬背」了訓練資料
```

**防止過擬合的方法：**
1. **增加資料**：最有效的方法
2. **減少特徵**：只保留最重要的特徵
3. **正則化**：限制模型複雜度
4. **交叉驗證**：更可靠的評估方法

---

### 5. 損失曲線（Loss Curve）

**在你的結果圖中：**
- `models/training_results.png` 的右下角
- 顯示訓練過程中 RMSE 的變化

**理想的損失曲線：**
```
RMSE
 │
 │ \
 │  \___  訓練損失
 │   \___  驗證損失
 │
 └────────────> Epoch
```

**你的曲線可能：**
```
RMSE
 │
 │ \___  訓練損失（快速下降）
 │
 │ ╱╲╱╲  驗證損失（不穩定）
 │
 └────────────> Epoch
```
→ 資料太少，驗證損失不穩定

---

### 6. 學習率（Learning Rate）

**XGBoost 中：**
- `learning_rate=0.1`：每棵樹貢獻 10% 的預測

**比喻：**
```
學習率 = 下山的步伐大小

太大（0.5）：
  ╱╲╱╲╱╲  跳來跳去，找不到最低點
 ╱      ╲

適中（0.1）：
  ╲
   ╲___  穩定下降到最低點

太小（0.01）：
  ╲
   ╲
    ╲  太慢，需要很多步
```

**調整建議：**
- 資料少：用較大的學習率（0.1-0.3）
- 資料多：用較小的學習率（0.01-0.05）

---

### 7. 訓練週期（Epochs / Iterations）

**XGBoost 中：**
- `n_estimators=100`：建立 100 棵樹（100 次迭代）

**神經網路中：**
- `epochs=100`：整個訓練集被訓練 100 次

**Early Stopping：**
```python
# 如果 20 次迭代沒有改善，提前停止
early_stopping_rounds=20
```

---

### 8. 誤差指標（Error Metrics）

#### RMSE（均方根誤差）
```
RMSE = √(平均(預測值 - 實際值)²)
```
- 你的測試集 RMSE = 5.76
- 意思：平均預測誤差約 5.76%

#### MAE（平均絕對誤差）
```
MAE = 平均(|預測值 - 實際值|)
```
- 你的測試集 MAE = 4.37
- 更直觀的誤差指標

#### R² Score（決定係數）
```
R² = 1 - (模型誤差 / 基準誤差)
```
- 範圍：-∞ 到 1
- 1.0 = 完美預測
- 0.0 = 跟隨機猜測一樣
- < 0 = 比隨機猜測還差！

**你的 R² = -2.0 表示：**
- 模型比「永遠預測平均值」還差 3 倍
- 需要更多資料！

---

## 🔧 改善建議

### 短期（資料少時）

1. **減少特徵數**
```python
# 只保留最重要的特徵
important_features = ['6個月低價距離 (%)', '5日高價距離 (%)', 
                     '盤前 (%)', '消息情緒分數', 'EPS Surprise (%)']
```

2. **簡化模型**
```python
.build_and_train_model(
    n_estimators=20,    # 減少到 20 棵樹
    max_depth=2,        # 只有 2 層深
    learning_rate=0.3   # 提高學習率
)
```

3. **使用交叉驗證**
```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=3)  # 3-fold CV
```

### 長期（收集更多資料）

1. **目標資料量**
   - 最少：100 筆
   - 理想：500-1000 筆
   - 最佳：5000+ 筆

2. **資料品質**
   - 確保資料準確性
   - 涵蓋不同市場情況
   - 平衡不同類型的股票

3. **特徵工程**
   - 加入更多技術指標
   - 計算特徵交互作用
   - 時間序列特徵

---

## 📊 特徵重要性解讀

你的模型顯示：

```
6個月低價距離 (%)  →  99.35%  重要性
5日高價距離 (%)    →   0.65%  重要性
其他特徵           →   0.00%  重要性
```

**這表示：**
- 模型幾乎只依賴「6個月低價距離」這一個特徵
- 其他 24 個特徵幾乎沒用
- 可能是因為資料太少，模型找到了一個「巧合」的關聯

---

## 🎓 總結

### 你問的概念都用到了！

| 概念 | 在 XGBoost 中 | 在神經網路中 |
|------|--------------|-------------|
| 神經數 | 樹的數量、深度 | 每層神經元數 |
| 訓練集/測試集 | ✓ 80/20 分割 | ✓ 80/20 分割 |
| 樣本數 | ✓ 6 筆（太少） | ✓ 6 筆（太少） |
| 噪音處理 | 樹的深度限制 | Dropout、正則化 |
| 損失曲線 | ✓ RMSE 曲線 | ✓ Loss 曲線 |
| 學習率 | ✓ 0.1 | ✓ 0.001 |
| 訓練週期 | ✓ 100 棵樹 | ✓ 100 epochs |
| 誤差 | ✓ RMSE, MAE, R² | ✓ MSE, MAE |

### 當前最大問題

**資料太少！** 6 筆資料無法訓練可靠的模型。

### 下一步

1. ✅ 你已經了解了整個訓練流程
2. ✅ 你知道如何解讀訓練結果
3. 📝 開始收集更多資料（目標：100+ 筆）
4. 🔄 隨著資料增加，模型會越來越準確

---

## 💡 實用技巧

### 如何判斷需要多少資料？

```
最少樣本數 ≈ 特徵數 × 10

你的情況：
25 個特徵 × 10 = 250 筆最少樣本
```

### 如何知道模型訓練得好？

```
✓ 訓練集 R² > 0.7
✓ 測試集 R² > 0.6
✓ 訓練集和測試集 R² 差距 < 0.2
✓ 損失曲線平穩下降
```

### 資料少時的替代方案

1. **特徵選擇**：只用 5-10 個最重要的特徵
2. **簡單模型**：線性回歸、決策樹
3. **領域知識**：用專家經驗設計規則
4. **數據增強**：合成新樣本（謹慎使用）

---

希望這份說明幫助你理解了機器學習訓練的核心概念！🚀
